\documentclass{standalone}

\begin{document}
  \subsection{Flaws in Implementation and Analysis}
  The biggest flaw in our experiments is that our implementations are not efficient. Most of the problems considered for this project can be solved very quickly using Matlab's \verb|linprog| function. \verb|linprog| uses the primal-dual simplex method whereas we use the primal simplex method. The result of the randomized simplex algorithms being faster needs to be verified with much more efficient implementations of all the pivot strategies so that we can rule out implementation flaws as the cause of the performance differences. The second important flaw is that our implementations are not necessarily numerically stable. We rely on Matlab to solve linear equations and use tolerances at certain points but do not take advantage of the linear algebra methods modern solvers use \cite{bixby2002solving}. A numerical method can only be as good as its implementation regardless of any promising theoretical properties it may have. Thus, we should also test our randomized methods with more stable methods so that we can determine whether randomized methods can always lead to instability or whether the instability is tied to the instability of the implementation. The issue of efficiency and stability are the main points that should be addressed in a future study. Additionally, improving efficiency will allow us to use Matlab's \verb|timeit| function which would be a better way of measuring performance as we would average the run times of the algorithms over $10$ attempts. Furthermore, improving efficiency will allow us to tackle larger problems and possibly also include a phase 1 linear program to our tests. This would give us a more hollistic overview of each strategy.\par
  Another flaw in the analysis is that the problems being considered are not necessarily suitable to be used with Clarkson's algorithm. We end up observing interesting behavior for the random edge and random facet algorithms but nothing significant happens with Clarkson's algorithm. In fact, Clarkson's algorithm behaves very similarly to the simplex method with Bland's rules but a little slower due to more overhead caused by the other parts of the algorithm. Either linear programs that have low dimensionality and a large number of constraints need to be generated or such problems ought to be found. One idea is to consider the problem given in the Netlib dataset and take their duals which in effect will flip the dimensionality. Since the problems in the Netlib set are bounded, by duality theory, the dual problems will also be bounded and have an unique minimal objective function value. Identifying such potential problems that satisfy the dimensionality requirements and running experiments on them could provide better insight into Clarkson's algorithm. Furthermore, Clarkson's other algorithm could also be considered along with Hansen's improved random facet \cite{hansen2015improved} and other algorithms presented in Goldwasser's survey of randomzied algorithms \cite{goldwasser1995survey}. Additionally, \cite{gartner1996linear} presents an interesting algorithm that combines Clarkson's algorithm with Kalai's. In fact, expanding the evaluation to other deterministic pivoting rules such as Zadeh's least-entered rule \cite{zadeh2009worst}, Cunningham's least recently considered rule \cite{cunningham1979theoretical} and Harris' devex rule \cite{harris1973pivot} could also be interesting. An exponential run-time lower bound was proven for Cunningham's rule recently in \cite{avis2017exponential} while \cite{friedmann2011subexponential} has proven a sub-exponential lower for Zadeh's rule. Both algorithms were proposed to defeat the problems caused by Klee-Minty cubes and comparing their performance against the randomized algorithms could be interesting.\par
  Overall, the flaws in our implementation and experimental evaluation define new directions for research. A more industrial implementation of the simplex method with randomization is the natural next step for this work.
  \subsection{Numerical Instability}
  We expand slightly on the issue of the numerical instability caused by the randomized methods. The issue of failure occurred more often during the initial phases of testing due to a lower tolerance level being used. Rather than relaxing this tolerance we proceeded with a different strategy. Before removing a constraint from the working set and adding a new blocking constraint in we checked whether the resulting matrix would be singular. If singularity/near-singularity was observed then the pivot was rejected and the simplex method moved to the next iteration without making progress. The idea here is that if there are multiple leaving constraints and multiple entering constraints then we should be able to repeat a randomized algorithm until a numerically non-singular new working set is found. This however works very poorly in practice. In fact for a small subset of the problems tested for this project we tried this strategy. The efficiency of both random facet and random edge were esentially lost as both methods started cycling. While we claim that that both methods cannot cycle under degeneracy a different kind of cycling was observed. With some probability both methods would perform a sequence of working set updates until reaching a point where any further exchanges would cause a singular matrix to be obtained so that the method would reject all updates and cycle until timing out. What is even worse is that the method would sometimes cycle at a point with an objective function value very near to the optimal value. This suggests that such a check cannot be useful most of the time as we cannot predict this behavior. Our observation is akin to the fact that it is hard to predict cycling under degeneracy for deterministic pivoting strategies. Thus, we proceeded to relax the tolerance levels which seems to have alleviated the issue somewhat. But, as can be seen in table \ref{tab:summary}, the issue has not been completely resolved and alternative strategies should be explored. 
\end{document}