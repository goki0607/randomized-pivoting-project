\documentclass{standalone}

\begin{document}
  \subsection{Result of Experiments}
  We give the results of running each pivoting strategy on each dataset considered. The tables for when Matlab throws an exception are omitted. However, if Matlab gives a singular matrix warning for a specific method this is recorded in the \verb|Failure| column of the table. The other columns are as explained in section \ref{sec:implementation} and we also note that the CPU Time measurement is given in seconds. Due to lack of time and the methods taking too long to complete, only a subset of the planned datasets have been tested. However, we have gathered plenty of data to make certain observational judgements and in total we test $31$ datasets. Table \ref{tab:summary} also provides a summary of certain results. For each method we record the number of times it lead to a singular matrix, the number of times an optimal solution was found, the number of times it reached its max iteration threshold and an optimal point was not found, the number of times it recorded the lowest objective value compared to the other methods and the average CPU running time (again measured in seconds). If a method fails for a dataset then we do not take into account any of the other measures for the summary table. However, if a method reaches the maximum number of iterations then we still consider all the measures as such runs are not failures. All tables except the summary table are given in the appendix section \ref{appendix:results} and the summary table is given below.
  \subsection{Summary Table}
  \begin{table}[H]
  \centering
  \begin{tabular}{@{}cccccc@{}}
  \toprule
  \makecell{Pivot\\Choice} & \makecell{Average\\CPU\\Time} & \makecell{Occurrences\\of\\ Optimal\\Solution} & \makecell{Occurrences\\of\\Max\\Iterations} & \makecell{Occurrences\\of\\Smallest\\Objective\\Value} & \makecell{Ocurrences\\of\\Failure} \\ \midrule
  Bland & 8185.170475 & 7 & \textbf{23} & 6 & 1 \\
  Danztig & 6238.237211 & \textbf{13} & 17 & 9 & 1 \\
  Steepest Edge & 11527.942982 & 10 & \underline{20} & \underline{10} & 1 \\
  Random Edge & \underline{982.143201} & \underline{12} & 10 & \textbf{18} & \textbf{8} \\
  Random Facet & \textbf{401.503758} & 9 & 19 & 8 & \underline{2} \\
  Clarkson & 9060.511167 & 7 & \textbf{23} & 6 & 1 \\ \bottomrule
  \end{tabular}
  \caption{Summary of all test runs.}
  \label{tab:summary}
  \end{table}
  In the table above we indicate the smallest Average CPU Time in bold and underline the second smallest Average CPU Time. For all other columns we bold the highest value and underline the second highest value.
  \subsection{Analysis of Results}
  From the summary table we see that on average, when the method does not cause a singular Matrix warning, the random facet method followed by the random edge strategy performs the best. It seems that random facet performs much more poorly compared to the other algorithms when the problem size is small. However, as the problem gets larger the CPU time of random facet is smaller compared to the others and for some cases such as in table \ref{tab:agg2} and table \ref{tab:boeing1} the difference is remarkable. A possible reason why this is happening could be that the random facet algorithm is randomly choosing optimal facets more often than those that are non-optimal which allows it to eliminate a lot of non-optimal facets quickly. Another reason why random facet could be better is that the algorithm builds an optimal working set bottom-up, i.e. from a smaller working set we get larger working sets, and only performs a pivot step fully if a facet is not optimal. In contrast, the simplex method with deterministic pivoting will complete a full $k$ iterations of pivoting until the optimal point is found but the random facet will only complete one full iteration if a facet is non-optimal. The second fastest strategy is random edge and this is also surprising. Here we know that the random edge algorithm is less computationally intensive compared to Dantzig's rule or the steepest edge rule and slightly more expensive compared to Bland's rules. This is because we only need to sample from an uniform distribution and there already exists efficient algorithms to do this. Beyond this reasoning there isn't much indication as to why random edge is performing so well. We theorize that it may have to do with the fact that random edge at any given point will behave like any of the three deterministic pivoting rules meaning that at any given point we are taking an optimal path with some probability. However, quantifying this probability is hard. We also see that Clarkson's algorithm performs the second worst which makes sense as most of the problems in the Netlib dataset \cite{netlibtest} does not satisfy the small dimensionality requirement. Recall that the small dimensionality requirement is the assumption that the dimensions of the problem, i.e. the number of variables, is greatly smaller than the number of constraints. From the deterministic pivoting rules the steepest edge rule performs the worst. This can be attributed to the fact that the implementation of steepest edge in appendix \ref{appendix:simplex} is naive. A more efficient algorithm as given in \cite{goldfarb1977practicable} and \cite{forrest1992steepest} should certainly decrease the run-time. Finally, Dantzig's rule performs better than Bland's rule and this is not surprising as this has been observed in practice many times. Overall, two of the presented randomized algorithms definitely show promise in terms of CPU run-time performance.\par
  We now turn our attention to the other columns of the summary table \ref{tab:summary}. We see that in terms of failing due to obtaining a singular working set the random edge method followed by the random facet method perform the poorest. In fact, the random edge method performs much worse in this scenario compared to the other methods. This high rate of failure can be primarily attributed to numerical instability caused by the inefficient implementations of the simplex method. However, this is only half of the story as we see that the deterministic strategies only fail once for some dataset. It seems that the random edge rule is causing numerical issues to become more pronounced and this phenemenon could be attributed to the randomness of the pivot rule. That is, if we obtain a set of possible constraints the deterministic methods will either choose the one that is most negative or has the least index which makes it much less likely to pick a ``faux'' index. On the other hand, if a Lagrange multiplier is a value such as \verb|-1e-5| then the random edge rule will pick this one with the same probability that it will pick a Lagrange multiplier that is a value such as \verb|-1e10|. Clearly \verb|-1e10| is the better choice in terms of both decreasing the value of the objective function and numerical stability as the number \verb|-1e10| definitely corresponds to a non-optimal constraint (unless there is some catastrophic issue relating to floating-point arithmetic or ill-conditioning). On the other hand, the value \verb|-1e-5| is ambigious as we can't with certainty tell that this is a multiplier of a non-optimal constraint. Thus, the random nature of random edge also makes it more unpredictable in terms of numerical stability. The same can be said for random facet but here the issue is not as dangerous as we do not always do a full pivot step. Clarkson's algorithm is stable and this is not surprising as it solves linear programs using Bland's rules which is also stable for these tests. Furthermore, the deterministic algorithms are also stable and the reasons for this have been discussed in the context of random edge's stability. Now we see that there might be a trade-off between stability and speed with randomized strategies.\par
  The three columns that measure the amount of times each strategy finds an optimal point, the number of times each strategy times out and the number of times each strategy finds the smallest objective value compared against the other methods attempt to compare each method with the others. Note that there are slightest disrepancies in the table due to floating point error. That is, two methods that satisfy the optimality conditions may report two different optimal objective function values due to accrued round-off error. We of course know that in theory the optimal objective function value is unique but in practice this may not be the case. In terms of finding an optimal solution both random edge and random facet work well and they are close to the deterministic stratgies Dantzig's rule and steepest edge rule. This observation shows us that the randomized rules can sometimes be as effective as their deterministic counterparts. In terms of timing out we see that both Bland's rules and Clarkson's method times out the most. It is known that Bland's rules in practice are slow and since we use the simplex method with Bland's rules as a subroutine for Clarkson's method we observe the same poor performance. It seems that Clarkson's method's performance not only depends on dimensionality of the problem but also the simplex implementation picked for the base case. Finally, the smallest objective value column attempts measures how much progress has been made by each method regardless of whether it has timed out or found an optimal objective function value. We see that random edge is the best in this case by a large margin but this difference can also be attributed to possible numerical instability. Since random edge appears to be unstable, it could also be accruing a lot of round-off errors making this measure an anomaly. The other methods behave the same with steepest edge being the second best in terms of making progress and is followed by Dantzig's rule. This is probably due to the fact that both algorithms actively try to reduce the objective value as much as possible from one iteration to another. We see that the random edge and random facet methods behave similarly to their deterministic counterparts while Clarkson's method's behavior closely follows the underlying solver being used for the base case.\par
  The experimental results show the promise of random edge and random facet for a general class of linear programming problems and backup their theoretical claims in terms of runtime. They can be potentially much faster than deterministic methods but seem to be also more susceptible to numerical instability. On the other hand, Clarkson's method has been dissapointing in the sense that it does not perform as well as the other two randomized algorithms. This suggests that a more specialized testing dataset with the ``right'' dimensions might be necessary to discover any potential benefits of the method. The deterministic algorithms mostly match our expectations of them and our results demonstrate why Dantzig's rule is a popular choice in the simplex method. The steepest edge rule could definitely be made with a more efficient implementation which would improve its metrics in table \ref{tab:summary}. Our results definitely call for more experimental evaluation where the experimental method is improved by addressing the shortcomings explain in the next section (\ref{sec:eval}).
\end{document}